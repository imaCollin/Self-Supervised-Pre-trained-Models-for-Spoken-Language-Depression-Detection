{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"11SPLZaaCdVPn-D0J_BdJnxzXpHcRqSwD","authorship_tag":"ABX9TyNEwVXWNupIchEU+BBrbPUi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Processing\n","### Loading Audio data using Librosa\n","### Data Cleaning\n","### Data Augmentation (i.e. increasing noise, time scaling)\n","### Either extracting conventional features (e.g., MFCC, mel-spectrogram) or applying features extracted from self-supervised models(e.g., wav2vec2, HuBERT)."],"metadata":{"id":"BbDXXOb_iEqd"}},{"cell_type":"code","source":["import os\n","import librosa\n","import numpy as np\n","import torch\n","from transformers import Wav2Vec2Processor, Wav2Vec2Model"],"metadata":{"id":"cXGPEFztkpwc","executionInfo":{"status":"ok","timestamp":1732228154103,"user_tz":-480,"elapsed":559,"user":{"displayName":"潘昱光","userId":"00418983213497725036"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Step 1: Loading Data and Implement Data Preprocessing"],"metadata":{"id":"oGrWBDQ_v6BC"}},{"cell_type":"code","source":["def load_audio(file_path, target_sr=16000):\n","    \"\"\"\n","    加载音频文件并重采样到目标采样率。\n","\n","    Args:\n","        file_path (str): 音频文件路径。\n","        target_sr (int): 目标采样率，默认为16000。\n","\n","    Returns:\n","        tuple: (信号数据, 采样率)\n","    \"\"\"\n","    try:\n","        signal, sr = librosa.load(file_path, sr=target_sr)\n","        return signal, sr\n","    except Exception as e:\n","        raise ValueError(f\"无法加载音频文件 {file_path}，错误信息: {e}\")"],"metadata":{"id":"JV4Izj1_lkxO","executionInfo":{"status":"ok","timestamp":1732228154103,"user_tz":-480,"elapsed":2,"user":{"displayName":"潘昱光","userId":"00418983213497725036"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Step 2: Feature Extraction"],"metadata":{"id":"W7mhNlP7l06p"}},{"cell_type":"code","source":["def extract_mfcc(signal, sr, n_mfcc=40):\n","    \"\"\"\n","    提取 MFCC 特征。\n","\n","    Args:\n","        signal (numpy.ndarray): 音频信号。\n","        sr (int): 采样率。\n","        n_mfcc (int): 要提取的MFCC特征数量，默认40。\n","\n","    Returns:\n","        numpy.ndarray: MFCC 特征。\n","    \"\"\"\n","    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n","    return mfcc\n","\n","def extract_mel_spectrogram(signal, sr, n_mels=128):\n","    \"\"\"\n","    提取 Mel-Spectrogram 特征。\n","\n","    Args:\n","        signal (numpy.ndarray): 音频信号。\n","        sr (int): 采样率。\n","        n_mels (int): Mel频谱图的频带数量，默认128。\n","\n","    Returns:\n","        numpy.ndarray: Mel-Spectrogram 特征。\n","    \"\"\"\n","    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=n_mels)\n","    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)  # 转换为对数刻度\n","    return mel_spec_db\n","\n","def extract_wav2vec2_features(signal, sr, model_name=\"facebook/wav2vec2-base-960h\"):\n","    \"\"\"\n","    使用 wav2vec2 提取高维特征。\n","\n","    Args:\n","        signal (numpy.ndarray): 音频信号。\n","        sr (int): 采样率。\n","        model_name (str): wav2vec2 模型名称，默认 \"facebook/wav2vec2-base-960h\"。\n","\n","    Returns:\n","        torch.Tensor: wav2vec2 特征。\n","    \"\"\"\n","    # 加载模型和处理器\n","    processor = Wav2Vec2Processor.from_pretrained(model_name)\n","    model = Wav2Vec2Model.from_pretrained(model_name)\n","\n","    # 转换为模型输入格式\n","    input_values = processor(signal, sampling_rate=sr, return_tensors=\"pt\", padding=True).input_values\n","\n","    # 提取特征\n","    with torch.no_grad():\n","        embeddings = model(input_values).last_hidden_state\n","    return embeddings"],"metadata":{"id":"qS0O5KKVl6EK","executionInfo":{"status":"ok","timestamp":1732228154103,"user_tz":-480,"elapsed":2,"user":{"displayName":"潘昱光","userId":"00418983213497725036"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Step 3: Optimization (Data Augmentation)"],"metadata":{"id":"s_Joes3mmI8I"}},{"cell_type":"code","source":["def add_noise(signal, noise_level=0.005):\n","    \"\"\"\n","    增加随机噪声。\n","\n","    Args:\n","        signal (numpy.ndarray): 音频信号。\n","        noise_level (float): 噪声强度，默认0.005。\n","\n","    Returns:\n","        numpy.ndarray: 增强后的音频信号。\n","    \"\"\"\n","    noise = noise_level * np.random.randn(len(signal))\n","    return signal + noise\n","\n","def time_stretch(signal, rate=1.1):\n","    \"\"\"\n","    改变音频的时间长度（时间缩放）。\n","\n","    Args:\n","        signal (numpy.ndarray): 音频信号。\n","        rate (float): 时间缩放比例，默认为1.1。\n","\n","    Returns:\n","        numpy.ndarray: 时间缩放后的音频信号。\n","    \"\"\"\n","    return librosa.effects.time_stretch(signal, rate)\n","\n","def pitch_shift(signal, sr, n_steps=2):\n","    \"\"\"\n","    改变音频的音调。\n","\n","    Args:\n","        signal (numpy.ndarray): 音频信号。\n","        sr (int): 采样率。\n","        n_steps (int): 音调变化的半音数，默认为2。\n","\n","    Returns:\n","        numpy.ndarray: 调整音调后的音频信号。\n","    \"\"\"\n","    return librosa.effects.pitch_shift(signal, sr, n_steps)"],"metadata":{"id":"hQQj-fCSmhY3","executionInfo":{"status":"ok","timestamp":1732228154103,"user_tz":-480,"elapsed":2,"user":{"displayName":"潘昱光","userId":"00418983213497725036"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Step 4: Batch processing of the audio files"],"metadata":{"id":"4sVXpZ1hoVJP"}},{"cell_type":"code","source":["def process_audio_file(file_path, feature_type=\"mfcc\", target_sr=16000, model_name=None):\n","    \"\"\"\n","    对单个音频文件进行特征提取。\n","\n","    Args:\n","        file_path (str): 音频文件路径。\n","        feature_type (str): 特征类型（\"mfcc\", \"mel\", \"wav2vec2\"）。\n","        target_sr (int): 目标采样率。\n","        model_name (str): wav2vec2 模型名称（仅当 feature_type=\"wav2vec2\" 时需要）。\n","\n","    Returns:\n","        numpy.ndarray 或 torch.Tensor: 提取的特征。\n","    \"\"\"\n","    signal, sr = load_audio(file_path, target_sr)\n","\n","    if feature_type == \"mfcc\":\n","        return extract_mfcc(signal, sr)\n","    elif feature_type == \"mel\":\n","        return extract_mel_spectrogram(signal, sr)\n","    elif feature_type == \"wav2vec2\":\n","        if model_name is None:\n","            raise ValueError(\"使用 wav2vec2 提取特征时必须提供 model_name\")\n","        return extract_wav2vec2_features(signal, sr, model_name)\n","    else:\n","        raise ValueError(f\"不支持的特征类型：{feature_type}\")\n","\n","def batch_process_audio_files(file_paths, feature_type=\"mfcc\", target_sr=16000, model_name=None):\n","    \"\"\"\n","    批量处理音频文件并提取特征。\n","\n","    Args:\n","        file_paths (list): 音频文件路径列表。\n","        feature_type (str): 特征类型（\"mfcc\", \"mel\", \"wav2vec2\"）。\n","        target_sr (int): 目标采样率。\n","        model_name (str): wav2vec2 模型名称（仅当 feature_type=\"wav2vec2\" 时需要）。\n","\n","    Returns:\n","        list: 提取的特征列表。\n","    \"\"\"\n","    features = []\n","    for file_path in file_paths:\n","        try:\n","            feature = process_audio_file(file_path, feature_type, target_sr, model_name)\n","            features.append(feature)\n","        except Exception as e:\n","            print(f\"处理文件 {file_path} 出错：{e}\")\n","    return features"],"metadata":{"id":"xNUoSzruogOM","executionInfo":{"status":"ok","timestamp":1732228154103,"user_tz":-480,"elapsed":2,"user":{"displayName":"潘昱光","userId":"00418983213497725036"}}},"execution_count":10,"outputs":[]}]}