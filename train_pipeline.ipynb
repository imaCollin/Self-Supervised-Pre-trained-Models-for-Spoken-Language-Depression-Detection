{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYUqaH8o1PPZpThqo/S5Fg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vjEYZPZYGRTn"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from dataset import create_data_loaders\n","from model import get_model\n","from sklearn.metrics import accuracy_score\n","from pathlib import Path\n","import json\n","\n","# ===============================\n","# 配置参数\n","# ===============================\n","\n","class Config:\n","    DATASET_DIR = \"./data/DAIC-WOZ\"  # 数据集目录，适配 DAIC-WOZ 或 EATD\n","    BATCH_SIZE = 32\n","    LEARNING_RATE = 0.001\n","    NUM_EPOCHS = 20\n","    MODEL_NAME = \"cnn_gru\"  # 支持 \"cnn_gru\" 或 \"simple_cnn\"\n","    FEATURE_TYPE = \"mfcc\"  # 支持 \"mfcc\", \"mel\", 或 \"wav2vec2\"\n","    TARGET_SR = 16000  # 目标采样率\n","    MODEL_SAVE_PATH = \"./best_model.pth\"  # 模型保存路径\n","    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# ===============================\n","# 数据加载函数\n","# ===============================\n","\n","def load_daic_woz_data(dataset_dir):\n","    \"\"\"\n","    加载 DAIC-WOZ 数据集的音频文件路径和标签。\n","\n","    Args:\n","        dataset_dir (str): 数据集目录路径。\n","\n","    Returns:\n","        tuple: (file_paths, labels)\n","    \"\"\"\n","    file_paths = []\n","    labels = []\n","\n","    # 假设音频文件和元数据位于子目录中\n","    for subdir in Path(dataset_dir).iterdir():\n","        if not subdir.is_dir():\n","            continue\n","\n","        # 加载元数据（假设有 `transcript.json` 或类似文件）\n","        metadata_file = subdir / \"transcript.json\"\n","        if metadata_file.exists():\n","            with open(metadata_file, \"r\") as f:\n","                metadata = json.load(f)\n","                label = metadata.get(\"PHQ8_binary\")  # 获取二分类标签（抑郁或非抑郁）\n","\n","                # 获取音频文件路径（假设主音频文件名为 `audio.wav`）\n","                audio_file = subdir / \"audio.wav\"\n","                if audio_file.exists():\n","                    file_paths.append(str(audio_file))\n","                    labels.append(label)\n","\n","    return file_paths, labels\n","\n","\n","# ===============================\n","# 训练函数\n","# ===============================\n","\n","def train_model():\n","    # 加载 DAIC-WOZ 数据集\n","    print(f\"Loading dataset from {Config.DATASET_DIR}...\")\n","    file_paths, labels = load_daic_woz_data(Config.DATASET_DIR)\n","\n","    # 检查数据是否加载成功\n","    if not file_paths or not labels:\n","        raise ValueError(f\"No data found in {Config.DATASET_DIR}!\")\n","\n","    print(f\"Loaded {len(file_paths)} samples from dataset.\")\n","\n","    # 创建数据加载器\n","    train_loader, val_loader, test_loader = create_data_loaders(\n","        file_paths, labels,\n","        batch_size=Config.BATCH_SIZE,\n","        feature_type=Config.FEATURE_TYPE,\n","        target_sr=Config.TARGET_SR\n","    )\n","\n","    # 加载模型\n","    print(f\"Initializing model: {Config.MODEL_NAME}...\")\n","    model = get_model(model_name=Config.MODEL_NAME, input_channels=1, num_classes=2).to(Config.DEVICE)\n","\n","    # 定义损失函数和优化器\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n","\n","    # 训练和验证\n","    best_val_accuracy = 0.0\n","    for epoch in range(Config.NUM_EPOCHS):\n","        # 训练阶段\n","        model.train()\n","        running_loss = 0.0\n","        for features, labels in train_loader:\n","            features, labels = features.to(Config.DEVICE), labels.to(Config.DEVICE)\n","\n","            # 前向传播\n","            outputs = model(features)\n","            loss = criterion(outputs, labels.long())\n","\n","            # 反向传播\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        avg_train_loss = running_loss / len(train_loader)\n","\n","        # 验证阶段\n","        model.eval()\n","        val_loss = 0.0\n","        all_labels = []\n","        all_preds = []\n","        with torch.no_grad():\n","            for features, labels in val_loader:\n","                features, labels = features.to(Config.DEVICE), labels.to(Config.DEVICE)\n","\n","                outputs = model(features)\n","                loss = criterion(outputs, labels.long())\n","                val_loss += loss.item()\n","\n","                preds = torch.argmax(outputs, dim=1)\n","                all_labels.extend(labels.cpu().numpy())\n","                all_preds.extend(preds.cpu().numpy())\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        val_accuracy = accuracy_score(all_labels, all_preds)\n","\n","        print(f\"Epoch {epoch+1}/{Config.NUM_EPOCHS}\")\n","        print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","\n","        # 保存最佳模型\n","        if val_accuracy > best_val_accuracy:\n","            best_val_accuracy = val_accuracy\n","            torch.save(model.state_dict(), Config.MODEL_SAVE_PATH)\n","            print(f\"Best model saved to {Config.MODEL_SAVE_PATH}\")\n","\n","    # 测试阶段\n","    model.load_state_dict(torch.load(Config.MODEL_SAVE_PATH))\n","    model.eval()\n","    all_labels = []\n","    all_preds = []\n","    with torch.no_grad():\n","        for features, labels in test_loader:\n","            features, labels = features.to(Config.DEVICE), labels.to(Config.DEVICE)\n","\n","            outputs = model(features)\n","            preds = torch.argmax(outputs, dim=1)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(preds.cpu().numpy())\n","\n","    test_accuracy = accuracy_score(all_labels, all_preds)\n","    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n","\n","\n","# ===============================\n","# 主函数\n","# ===============================\n","if __name__ == \"__main__\":\n","    train_model()"]}]}